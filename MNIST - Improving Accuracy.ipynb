{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I decided to try a different gradient descent method namely - ADAM optimizer. I read the following paper: https://arxiv.org/pdf/1412.6980.pdf and discovered that it combines the benefits of two extensions of gradient descent - AdaGrad and RMSProp which both already perform better than regular stochastic gradient descent. Initially I thought of applying learning rate decay in pairing with Adam but I found out that the ADAM optimizer already does apply some form of decay and that learning rate decay does not work particulary well with it. \n",
    "\n",
    "So next I read a few papers including: http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer which convinced me that adding a dropout to the existing logistic regression model in Q2 might give an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Average loss epoch 0: 0.3694290117575572\n",
      "Average loss epoch 1: 0.2940027995473577\n",
      "Average loss epoch 2: 0.28625442794500255\n",
      "Average loss epoch 3: 0.2805714821204161\n",
      "Average loss epoch 4: 0.2733050552489874\n",
      "Average loss epoch 5: 0.27337993287192636\n",
      "Average loss epoch 6: 0.271167913881632\n",
      "Average loss epoch 7: 0.2651257185495539\n",
      "Average loss epoch 8: 0.2663134197532992\n",
      "Average loss epoch 9: 0.2669349051751457\n",
      "Total time: 25.237061977386475 seconds\n",
      "Optimization Finished!\n",
      "Accuracy 0.922\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple logistic regression model to solve OCR task \n",
    "with MNIST in TensorFlow\n",
    "MNIST dataset: yann.lecun.com/exdb/mnist/\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time\n",
    "\n",
    "# Define paramaters for the model\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "n_epochs = 10\n",
    "DROPOUT = 0.75\n",
    "\n",
    "# Step 1: Read in data\n",
    "# using TF Learn's built in function to load MNIST data to the folder MNIST_data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "\n",
    "# Step 2: create placeholders for features and labels\n",
    "# each image in the MNIST data is of shape 28*28 = 784\n",
    "# therefore, each image is represented with a 1x784 tensor\n",
    "# there are 10 classes for each image, corresponding to digits 0 - 9. \n",
    "# each lable is one hot vector.\n",
    "X = tf.placeholder(tf.float32, [batch_size, 784], name='X_placeholder') \n",
    "Y = tf.placeholder(tf.int32, [batch_size, 10], name='Y_placeholder')\n",
    "\n",
    "#dropout = tf.placeholder(tf.float32, name='dropout') #added placeholder for dropout\n",
    "\n",
    "# Step 3: create weights and bias\n",
    "# w is initialized to random variables with mean of 0, stddev of 0.01\n",
    "# b is initialized to 0\n",
    "# shape of w depends on the dimension of X and Y so that Y = tf.matmul(X, w)\n",
    "# shape of b depends on Y\n",
    "w = tf.Variable(tf.random_normal(shape=[784, 10], stddev=0.01), name='weights')\n",
    "b = tf.Variable(tf.zeros([1, 10]), name=\"bias\")\n",
    "\n",
    "# Step 4: build model\n",
    "# the model that returns the logits.\n",
    "# this logits will be later passed through softmax layer\n",
    "# to get the probability distribution of possible label of the image\n",
    "# DO NOT DO SOFTMAX HERE\n",
    "logits = tf.matmul(X, w) + b \n",
    "    # apply dropout\n",
    "#logits = tf.nn.dropout(logits, dropout, name='logit_dropout')\n",
    "\n",
    "\n",
    "# Step 5: define loss function\n",
    "# use cross entropy loss of the real labels with the softmax of logits\n",
    "# use the method:\n",
    "# tf.nn.softmax_cross_entropy_with_logits(logits, Y)\n",
    "# then use tf.reduce_mean to get the mean loss of the batch\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y, name='loss')\n",
    "loss = tf.reduce_mean(entropy) # computes the mean over all the examples in the batch\n",
    "\n",
    "# Step 6: define training op\n",
    "# using gradient descent to minimize loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('./graphs/logistic_reg_adam', sess.graph) # to visualize using TensorBoard\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\t\n",
    "    n_batches = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(n_epochs): # train the model n_epochs times\n",
    "        total_loss = 0\n",
    "\n",
    "        for _ in range(n_batches):\n",
    "            X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "            _, loss_batch = sess.run([optimizer, loss], feed_dict={X: X_batch, Y:Y_batch})\n",
    "            total_loss += loss_batch\n",
    "        print('Average loss epoch {0}: {1}'.format(i, total_loss/n_batches))\n",
    "\n",
    "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "    print('Optimization Finished!') # should be around 0.35 after 25 epochs\n",
    "\n",
    "    # test the model\n",
    "    n_batches = int(mnist.test.num_examples/batch_size)\n",
    "    total_correct_preds = 0\n",
    "    for i in range(n_batches):\n",
    "        X_batch, Y_batch = mnist.test.next_batch(batch_size)\n",
    "        _, loss_batch, logits_batch = sess.run([optimizer, loss, logits], feed_dict={X: X_batch, Y:Y_batch})\n",
    "        preds = tf.nn.softmax(logits_batch)\n",
    "        correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y_batch, 1))\n",
    "        accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32)) # need numpy.count_nonzero(boolarr) :(\n",
    "        total_correct_preds += sess.run(accuracy)\n",
    "\n",
    "    print('Accuracy {0}'.format(total_correct_preds/mnist.test.num_examples))\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just using the Adam Optimizer gave an improvement of 3% to Q2 already! Next, I tried to just add a dropout right after the logit calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Average loss epoch 0: 0.49359347457652325\n",
      "Average loss epoch 1: 0.4241667569795133\n",
      "Average loss epoch 2: 0.4136645319092246\n",
      "Average loss epoch 3: 0.40891095075435013\n",
      "Average loss epoch 4: 0.40767555953044715\n",
      "Average loss epoch 5: 0.4000908545889221\n",
      "Average loss epoch 6: 0.39604884045663136\n",
      "Average loss epoch 7: 0.39657562380626205\n",
      "Average loss epoch 8: 0.39040603216016767\n",
      "Average loss epoch 9: 0.3891108722397775\n",
      "Total time: 30.05392813682556 seconds\n",
      "Optimization Finished!\n",
      "Accuracy 0.8736\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple logistic regression model to solve OCR task \n",
    "with MNIST in TensorFlow\n",
    "MNIST dataset: yann.lecun.com/exdb/mnist/\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time\n",
    "\n",
    "# Define paramaters for the model\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "n_epochs = 10\n",
    "DROPOUT = 0.75\n",
    "\n",
    "# Step 1: Read in data\n",
    "# using TF Learn's built in function to load MNIST data to the folder MNIST_data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "\n",
    "# Step 2: create placeholders for features and labels\n",
    "# each image in the MNIST data is of shape 28*28 = 784\n",
    "# therefore, each image is represented with a 1x784 tensor\n",
    "# there are 10 classes for each image, corresponding to digits 0 - 9. \n",
    "# each lable is one hot vector.\n",
    "X = tf.placeholder(tf.float32, [batch_size, 784], name='X_placeholder') \n",
    "Y = tf.placeholder(tf.int32, [batch_size, 10], name='Y_placeholder')\n",
    "\n",
    "dropout = tf.placeholder(tf.float32, name='dropout') #added placeholder for dropout\n",
    "\n",
    "# Step 3: create weights and bias\n",
    "# w is initialized to random variables with mean of 0, stddev of 0.01\n",
    "# b is initialized to 0\n",
    "# shape of w depends on the dimension of X and Y so that Y = tf.matmul(X, w)\n",
    "# shape of b depends on Y\n",
    "w = tf.Variable(tf.random_normal(shape=[784, 10], stddev=0.01), name='weights')\n",
    "b = tf.Variable(tf.zeros([1, 10]), name=\"bias\")\n",
    "\n",
    "# Step 4: build model\n",
    "# the model that returns the logits.\n",
    "# this logits will be later passed through softmax layer\n",
    "# to get the probability distribution of possible label of the image\n",
    "# DO NOT DO SOFTMAX HERE\n",
    "logits = tf.matmul(X, w) + b \n",
    "    # apply dropout\n",
    "logits = tf.nn.dropout(logits, dropout, name='logit_dropout')\n",
    "\n",
    "\n",
    "# Step 5: define loss function\n",
    "# use cross entropy loss of the real labels with the softmax of logits\n",
    "# use the method:\n",
    "# tf.nn.softmax_cross_entropy_with_logits(logits, Y)\n",
    "# then use tf.reduce_mean to get the mean loss of the batch\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y, name='loss')\n",
    "loss = tf.reduce_mean(entropy) # computes the mean over all the examples in the batch\n",
    "\n",
    "# Step 6: define training op\n",
    "# using gradient descent to minimize loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('./graphs/logistic_reg_dropout', sess.graph) # to visualize using TensorBoard\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\t\n",
    "    n_batches = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(n_epochs): # train the model n_epochs times\n",
    "        total_loss = 0\n",
    "\n",
    "        for _ in range(n_batches):\n",
    "            X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "            _, loss_batch = sess.run([optimizer, loss], feed_dict={X: X_batch, Y:Y_batch, dropout: DROPOUT})\n",
    "            total_loss += loss_batch\n",
    "        print('Average loss epoch {0}: {1}'.format(i, total_loss/n_batches))\n",
    "\n",
    "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "    print('Optimization Finished!') # should be around 0.35 after 25 epochs\n",
    "\n",
    "    # test the model\n",
    "    n_batches = int(mnist.test.num_examples/batch_size)\n",
    "    total_correct_preds = 0\n",
    "    for i in range(n_batches):\n",
    "        X_batch, Y_batch = mnist.test.next_batch(batch_size)\n",
    "        _, loss_batch, logits_batch = sess.run([optimizer, loss, logits], feed_dict={X: X_batch, Y:Y_batch,dropout: DROPOUT})\n",
    "        preds = tf.nn.softmax(logits_batch)\n",
    "        correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y_batch, 1))\n",
    "        accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32)) # need numpy.count_nonzero(boolarr) :(\n",
    "        total_correct_preds += sess.run(accuracy)\n",
    "\n",
    "    print('Accuracy {0}'.format(total_correct_preds/mnist.test.num_examples))\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My naive use of dropout resulted in a  drop in performance of the model so more research was required into how exactly dropout needs to be used along with logistic regression (or if it even is a good fit with logistic regression) I tried several values for the dropout probability and all resulted in worse performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I read online that K-means algorithm gives up to 97% accuracy on the MNIST dataset so I tried running that next on the dataset. This requires data-set preprocessing using: deskewing, noise removal, blurring, 2 pixel shift according to: http://yann.lecun.com/exdb/mnist/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEX4gKMIPBEX4gaAIPxAU4QeC+n9NtlByfRAtkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c363921d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "data = mnist.train.images\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#plot = plt.imshow(full_data_x[1].reshape(28,28)) # This is what the image looks like\n",
    "\n",
    "from scipy.ndimage import interpolation\n",
    "def moments(image):\n",
    "    c0,c1 = np.mgrid[:image.shape[0],:image.shape[1]] # A trick in numPy to create a mesh grid\n",
    "    totalImage = np.sum(image) #sum of pixels\n",
    "    m0 = np.sum(c0*image)/totalImage #mu_x\n",
    "    m1 = np.sum(c1*image)/totalImage #mu_y\n",
    "    m00 = np.sum((c0-m0)**2*image)/totalImage #var(x)\n",
    "    m11 = np.sum((c1-m1)**2*image)/totalImage #var(y)\n",
    "    m01 = np.sum((c0-m0)*(c1-m1)*image)/totalImage #covariance(x,y)\n",
    "    mu_vector = np.array([m0,m1]) # Notice that these are \\mu_x, \\mu_y respectively\n",
    "    covariance_matrix = np.array([[m00,m01],[m01,m11]]) # Do you see a similarity between the covariance matrix\n",
    "    return mu_vector, covariance_matrix\n",
    "\n",
    "def deskew(image):\n",
    "    c,v = moments(image)\n",
    "    alpha = v[0,1]/v[0,0]\n",
    "    affine = np.array([[1,0],[alpha,1]])\n",
    "    ocenter = np.array(image.shape)/2.0\n",
    "    offset = c-np.dot(affine,ocenter)\n",
    "    return interpolation.affine_transform(image,affine,offset=offset)\n",
    "\n",
    "def deskewAll(X):\n",
    "    currents = []\n",
    "    for i in range(len(X)):\n",
    "        currents.append(deskew(X[i].reshape(28,28)).flatten())\n",
    "    return np.array(currents)\n",
    "plt.imshow(data[1].reshape(28,28)) # This is what the image looks like\n",
    "deskewed_data = deskewAll(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell shows the data before deskewing and the below one shows the data after deskewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c3da3c6d8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyKn/BzcFSpri8z6+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c3de39320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(deskewed_data[1].reshape(28,28)) # This is what the image looks like after deskewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" K-Means.\n",
    "Implement K-Means algorithm with TensorFlow, and apply it to classify\n",
    "handwritten digit images. This example is using the MNIST database of\n",
    "handwritten digits as training samples (http://yann.lecun.com/exdb/mnist/).\n",
    "Note: This example requires TensorFlow v1.1.0 or over.\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.factorization import KMeans\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# Import MNIST data\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "#data = mnist.train.images\n",
    "def kmeans(data,test_x,test_y):\n",
    "    # Parameters\n",
    "    num_steps = 100 \n",
    "    batch_size = 1024 \n",
    "    k = 50 \n",
    "    num_classes = 10 \n",
    "    num_features = 784 \n",
    "\n",
    "    #Input \n",
    "    X = tf.placeholder(tf.float32, shape=[None, num_features])\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, num_classes])\n",
    "\n",
    "    # K-Means Parameters\n",
    "    kmeans = KMeans(inputs=X, num_clusters=k, distance_metric='cosine',\n",
    "                    use_mini_batch=True)\n",
    "\n",
    "    # Build KMeans graph\n",
    "    training_graph = kmeans.training_graph()\n",
    "\n",
    "    if len(training_graph) > 6: \n",
    "        (all_scores, cluster_idx, scores, cluster_centers_initialized,\n",
    "         cluster_centers_var, init_op, train_op) = training_graph\n",
    "    else:\n",
    "        (all_scores, cluster_idx, scores, cluster_centers_initialized,\n",
    "         init_op, train_op) = training_graph\n",
    "\n",
    "    cluster_idx = cluster_idx[0] # fix for cluster_idx being a tuple\n",
    "    avg_distance = tf.reduce_mean(scores)\n",
    "\n",
    "    init_vars = tf.global_variables_initializer()\n",
    "\n",
    "    # Start TensorFlow session\n",
    "    sess = tf.Session()\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init_vars, feed_dict={X: data})\n",
    "    sess.run(init_op, feed_dict={X: data})\n",
    "\n",
    "    # Training\n",
    "    for i in range(1, num_steps + 1):\n",
    "        _, d, idx = sess.run([train_op, avg_distance, cluster_idx],\n",
    "                             feed_dict={X: data})\n",
    "        if i % 10 == 0 or i == 1:\n",
    "            print(\"Step %i, Avg Distance: %f\" % (i, d))\n",
    "\n",
    "    # Assign a label to each centroid\n",
    "    # Count total number of labels per centroid, using the label of each training\n",
    "    # sample to their closest centroid (given by 'idx')\n",
    "    counts = np.zeros(shape=(k, num_classes))\n",
    "    for i in range(len(idx)):\n",
    "        counts[idx[i]] += mnist.train.labels[i]\n",
    "    # Assign the most frequent label to the centroid\n",
    "    labels_map = [np.argmax(c) for c in counts]\n",
    "    labels_map = tf.convert_to_tensor(labels_map)\n",
    "\n",
    "    # Evaluation ops\n",
    "    # Lookup: centroid_id -> label\n",
    "    cluster_label = tf.nn.embedding_lookup(labels_map, cluster_idx)\n",
    "    # Compute accuracy\n",
    "    correct_prediction = tf.equal(cluster_label, tf.cast(tf.argmax(Y, 1), tf.int32))\n",
    "    accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    # Test Model\n",
    "    #test_x, test_y = mnist.test.images, mnist.test.labels\n",
    "    print(\"Test Accuracy:\", sess.run(accuracy_op, feed_dict={X: test_x, Y: test_y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADydJREFUeJzt3X+QVfV5x/HPw7osCQQUjEgQgz8gFWGKdYNtsAmVmmoS\ng2mKkXYcOmNdk9GOmcl0tExnxMm0ITbROKkxWQMVZ4whk8RKiYk6yJQmWmQxRjBrI3FQFghoSAIY\niyz79I89ZDa453sv9557z4Xn/Zpx9t7z3LPnmYufe+7d7/ner7m7AMQzouwGAJSD8ANBEX4gKMIP\nBEX4gaAIPxAU4QeCIvxAUIQfCOqkZh5spHX4KI1u5iGBUP5Pr+tNP2jVPLau8JvZZZLuktQm6evu\nviz1+FEarYtsfj2HBJCwwddW/dia3/abWZukuyVdLmmGpEVmNqPW3weguer5zD9H0lZ3f8nd35T0\nTUkLimkLQKPVE/7JkrYPud+Xbfs9ZtZlZj1m1nNIB+s4HIAi1RP+4f6o8Jb5we7e7e6d7t7Zro46\nDgegSPWEv0/SlCH3z5C0s752ADRLPeHfKGmamZ1lZiMlXS1pdTFtAWi0mof63L3fzG6U9KgGh/pW\nuPvzhXUGoKHqGud390ckPVJQLwCaiMt7gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/\nEBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAI\nPxAU4QeCIvxAUIQfCKquVXrNbJuk/ZIOS+p3984imkLztM2Ynqy/8KlTkvUX//KeZH1AnlsbIUvu\n+5Vfn5Wsr7zjQ8n6hOVPJevR1RX+zJ+5+2sF/B4ATcTbfiCoesPvkh4zs01m1lVEQwCao963/XPd\nfaeZnSbpcTN7wd3XD31A9qLQJUmj9PY6DwegKHWd+d19Z/Zzj6SHJM0Z5jHd7t7p7p3t6qjncAAK\nVHP4zWy0mb3jyG1JH5S0pajGADRWPW/7J0p6yMyO/J5vuPsPCukKQMOZe/44bNHG2ni/yOY37XhR\nnDTljNzaT289Pbnvg5d8LVm/oGMgWR9R4c3jgPL3r2dfSVrz+oRkfcUlf5pb6+/bkdz3eLXB12qf\n701fQJFhqA8IivADQRF+ICjCDwRF+IGgCD8QVBGz+tBgL93+J8n6C39zd24tNaVWqjytdqDC+eF7\nvx2XrD994OxkPeXC0duS9Y+P2Zes73w0/5qzNeenpypHwJkfCIrwA0ERfiAowg8ERfiBoAg/EBTh\nB4JinP84sPDSHyXrqbH8StNiK73+3/3rc5L1x//i/GS9nqmzP7ri6mT9o19Nf21418lbc2tr9N6a\nejqRcOYHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY528Fc2Yly5+ckB7P/t5v87+eu9J8+i373pWs\nH/yHdybrP7+9LVmf/tn8JdoO976Y3HfUfz6drLd/LX3sQ4mvMthx8/uS+07+/JPJ+omAMz8QFOEH\ngiL8QFCEHwiK8ANBEX4gKMIPBFVxnN/MVkj6iKQ97j4z2zZe0ipJUyVtk3SVu/+qcW2e4J7enCx3\nffxTyXrbrr25tcrz6X+RrO64OX2dQO8HvpysX37vdbm1tt7krvrlten1Cg75pmQ99V0G737g5eS+\n/cnqiaGaM/99ki47atstkta6+zRJa7P7AI4jFcPv7uslHX1qWSBpZXZ7paQrC+4LQIPV+pl/orvv\nkqTs52nFtQSgGRp+bb+ZdUnqkqRRyr/OG0Bz1Xrm321mkyQp+7kn74Hu3u3une7e2a6OGg8HoGi1\nhn+1pMXZ7cWSHi6mHQDNUjH8ZvagpKckvcfM+szsWknLJF1qZi9KujS7D+A4UvEzv7svyinNL7gX\n5PCN6esAGjkmPeq1xKR4Sd2/mZqsj9x9ILf20m3pOfX3XZO+hmCELFnfdDD/3FbPegInCq7wA4Ii\n/EBQhB8IivADQRF+ICjCDwTFV3efAN5YMCe3tvcP0v/ElYbyJmzOH6qTpK5x25L12Wvyp87O6Ugf\nu9Ly4hsTQ3mS9E/XJqYT65nkvhFw5geCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnPwHs/MSbubXe\nD6SX9640LXZA6bH4SvunxvLrmZIrSdd8+8Zk/ex1TyXr0XHmB4Ii/EBQhB8IivADQRF+ICjCDwRF\n+IGgGOc/wVWaE1/p9b+R+3dtvyS57/Z/nJasM45fH878QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBU\nxXF+M1sh6SOS9rj7zGzbUknXSXo1e9gSd3+kUU0i7V2rRubWFk6+IrnvzLE7k/VPTngyWZ/c9vZk\nPXV++fnnzkvu+bZ1T1f43ahHNWf++yRdNsz2O919dvYfwQeOMxXD7+7rJe1tQi8Amqiez/w3mtlz\nZrbCzE4prCMATVFr+O+RdI6k2ZJ2Sfpi3gPNrMvMesys55AO1ng4AEWrKfzuvtvdD7v7gKR7JeWu\nFOnu3e7e6e6d7eqotU8ABasp/GY2acjdj0naUkw7AJqlmqG+ByXNk3SqmfVJulXSPDObLcklbZN0\nfQN7BNAA5p7+XvYijbXxfpHNb9rxUD9776xkff9nX0/Wn5i1Krd2254Lk/v+5IopyXp/345kPaIN\nvlb7fG96QYQMV/gBQRF+ICjCDwRF+IGgCD8QFOEHguKru6t00pQzcmv92/ua2Elz+cbNyfqY4eZ7\nDrHwv/KnFD90bnoy6My/uzhZP3MpQ3314MwPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzp95Y0Hu\nlxFJki5e+j+5tTUvn5/cd9KVvTX1dCL4zRfOzK0NfDU9nfzQtDeKbgdDcOYHgiL8QFCEHwiK8ANB\nEX4gKMIPBEX4gaDCjPOn5uNL0ic+9/1kvWff1Nxa5HH8tpPHJet/tezR3NoIVfUN02gQzvxAUIQf\nCIrwA0ERfiAowg8ERfiBoAg/EFTFcX4zmyLpfkmnSxqQ1O3ud5nZeEmrJE2VtE3SVe7+q8a1Wp+X\n/zp/XrkkdY17OFm/88d/nls7Rz+uqafjwpz0Et2X//v6ZL3r5K25tYEK5572n70tWUd9qjnz90v6\njLufJ+mPJd1gZjMk3SJprbtPk7Q2uw/gOFEx/O6+y92fyW7vl9QrabKkBZJWZg9bKenKRjUJoHjH\n9JnfzKZKukDSBkkT3X2XNPgCIem0opsD0DhVh9/Mxkj6jqRPu/u+Y9ivy8x6zKznkA7W0iOABqgq\n/GbWrsHgP+Du38027zazSVl9kqQ9w+3r7t3u3unune3qKKJnAAWoGH4zM0nLJfW6+x1DSqslLc5u\nL5aU/nM5gJZSzZTeuZKukbTZzJ7Nti2RtEzSt8zsWkmvSFrYmBaLMXnd/mS9/aa2ZP2m2U/k1pb/\n/YeT+054Pv1x56QnNiXrlbTNmJ5b2zn/1OS+Yz78i2R93az7kvVK03JTw3nTv399ct/ptz2ZrKM+\nFcPv7j+Ucv+F5xfbDoBm4Qo/ICjCDwRF+IGgCD8QFOEHgiL8QFDmnl4muUhjbbxfZK05OnjgB2cn\n60/MWpVbG1HhNXRAA8n6bXsuTNYr+ei4/CnFF3Skj11v75X2f8+3b8itnfev25P79vftSNbxVht8\nrfb53qq+E50zPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTh/ptIS3n+4+pXc2r9MfC657yE/nKxX\nnhOf/jdK7V9p392H30jWv/LL9yXrj/3b3GR9wvKnknUUi3F+ABURfiAowg8ERfiBoAg/EBThB4Ii\n/EBQ1Xxvfwj92/uS9Z9cMSW3du7n65uP3zvv68n6+5+7Kll/de/Ymo997pf6k3XfuDlZnyDG8Y9X\nnPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKiK8/nNbIqk+yWdLmlAUre732VmSyVdJ+nV7KFL3P2R\n1O9q5fn8wIngWObzV3ORT7+kz7j7M2b2DkmbzOzxrHanu3+h1kYBlKdi+N19l6Rd2e39ZtYraXKj\nGwPQWMf0md/Mpkq6QNKGbNONZvacma0ws1Ny9ukysx4z6zmkg3U1C6A4VYffzMZI+o6kT7v7Pkn3\nSDpH0mwNvjP44nD7uXu3u3e6e2e7OgpoGUARqgq/mbVrMPgPuPt3Jcndd7v7YXcfkHSvpDmNaxNA\n0SqG38xM0nJJve5+x5Dtk4Y87GOSthTfHoBGqeav/XMlXSNps5k9m21bImmRmc2W5JK2Sbq+IR0C\naIhq/tr/Q2nYL4ZPjukDaG1c4QcERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q\nFOEHgiL8QFCEHwiq4ld3F3ows1clvTxk06mSXmtaA8emVXtr1b4keqtVkb29293fWc0Dmxr+txzc\nrMfdO0trIKFVe2vVviR6q1VZvfG2HwiK8ANBlR3+7pKPn9KqvbVqXxK91aqU3kr9zA+gPGWf+QGU\npJTwm9llZva/ZrbVzG4po4c8ZrbNzDab2bNm1lNyLyvMbI+ZbRmybbyZPW5mL2Y/h10mraTelprZ\njuy5e9bMPlRSb1PMbJ2Z9ZrZ82Z2U7a91Ocu0Vcpz1vT3/abWZukn0m6VFKfpI2SFrn7T5vaSA4z\n2yap091LHxM2s/dLOiDpfnefmW27XdJed1+WvXCe4u43t0hvSyUdKHvl5mxBmUlDV5aWdKWkv1WJ\nz12ir6tUwvNWxpl/jqSt7v6Su78p6ZuSFpTQR8tz9/WS9h61eYGkldntlRr8n6fpcnprCe6+y92f\nyW7vl3RkZelSn7tEX6UoI/yTJW0fcr9PrbXkt0t6zMw2mVlX2c0MY2K2bPqR5dNPK7mfo1VcubmZ\njlpZumWeu1pWvC5aGeEfbvWfVhpymOvufyTpckk3ZG9vUZ2qVm5ulmFWlm4Jta54XbQywt8nacqQ\n+2dI2llCH8Ny953Zzz2SHlLrrT68+8giqdnPPSX38zuttHLzcCtLqwWeu1Za8bqM8G+UNM3MzjKz\nkZKulrS6hD7ewsxGZ3+IkZmNlvRBtd7qw6slLc5uL5b0cIm9/J5WWbk5b2VplfzctdqK16Vc5JMN\nZXxJUpukFe7+z01vYhhmdrYGz/bS4CKm3yizNzN7UNI8Dc762i3pVkn/Ielbks6U9Iqkhe7e9D+8\n5fQ2T4NvXX+3cvORz9hN7u1iSf8tabOkgWzzEg1+vi7tuUv0tUglPG9c4QcExRV+QFCEHwiK8ANB\nEX4gKMIPBEX4gaAIPxAU4QeC+n9NtlByfRAtkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c34e6aba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[1].reshape(28,28)) # This is what the image looks like\n",
    "test_x, test_y = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Avg Distance: 0.314557\n",
      "Step 10, Avg Distance: 0.198182\n",
      "Step 20, Avg Distance: 0.196513\n",
      "Step 30, Avg Distance: 0.195821\n",
      "Step 40, Avg Distance: 0.195415\n",
      "Step 50, Avg Distance: 0.195135\n",
      "Step 60, Avg Distance: 0.194927\n",
      "Step 70, Avg Distance: 0.194766\n",
      "Step 80, Avg Distance: 0.194634\n",
      "Step 90, Avg Distance: 0.194525\n",
      "Step 100, Avg Distance: 0.194433\n",
      "Test Accuracy: 0.8106\n"
     ]
    }
   ],
   "source": [
    "kmeans(data,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Avg Distance: 0.240252\n",
      "Step 10, Avg Distance: 0.150108\n",
      "Step 20, Avg Distance: 0.148725\n",
      "Step 30, Avg Distance: 0.148210\n",
      "Step 40, Avg Distance: 0.147925\n",
      "Step 50, Avg Distance: 0.147734\n",
      "Step 60, Avg Distance: 0.147597\n",
      "Step 70, Avg Distance: 0.147492\n",
      "Step 80, Avg Distance: 0.147407\n",
      "Step 90, Avg Distance: 0.147337\n",
      "Step 100, Avg Distance: 0.147278\n",
      "Test Accuracy: 0.7456\n"
     ]
    }
   ],
   "source": [
    "deskewed_data = deskewAll(data)\n",
    "deskewed_test = deskewAll(test_x)\n",
    "kmeans(deskewed_data,deskewed_test,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-81-fab9baccd17b>:60: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Average loss epoch 0: 0.23488830577903416\n",
      "Average loss epoch 1: 0.17548192600721801\n",
      "Average loss epoch 2: 0.16896061236277604\n",
      "Average loss epoch 3: 0.1634677822217519\n",
      "Average loss epoch 4: 0.16235141897691296\n",
      "Average loss epoch 5: 0.15839735227517593\n",
      "Average loss epoch 6: 0.15477754628515883\n",
      "Average loss epoch 7: 0.1537764998487173\n",
      "Average loss epoch 8: 0.15405338552795647\n",
      "Average loss epoch 9: 0.15064912488671034\n",
      "Total time: 244.29588913917542 seconds\n",
      "Optimization Finished!\n",
      "Accuracy 0.9509\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple logistic regression model to solve OCR task \n",
    "with MNIST in TensorFlow\n",
    "MNIST dataset: yann.lecun.com/exdb/mnist/\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time\n",
    "\n",
    "# Define paramaters for the model\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "n_epochs = 10\n",
    "#DROPOUT = 0.75\n",
    "\n",
    "# Step 1: Read in data\n",
    "# using TF Learn's built in function to load MNIST data to the folder MNIST_data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "\n",
    "# Step 2: create placeholders for features and labels\n",
    "# each image in the MNIST data is of shape 28*28 = 784\n",
    "# therefore, each image is represented with a 1x784 tensor\n",
    "# there are 10 classes for each image, corresponding to digits 0 - 9. \n",
    "# each lable is one hot vector.\n",
    "X = tf.placeholder(tf.float32, [batch_size, 784], name='X_placeholder') \n",
    "Y = tf.placeholder(tf.int32, [batch_size, 10], name='Y_placeholder')\n",
    "\n",
    "#dropout = tf.placeholder(tf.float32, name='dropout') #added placeholder for dropout\n",
    "\n",
    "# Step 3: create weights and bias\n",
    "# w is initialized to random variables with mean of 0, stddev of 0.01\n",
    "# b is initialized to 0\n",
    "# shape of w depends on the dimension of X and Y so that Y = tf.matmul(X, w)\n",
    "# shape of b depends on Y\n",
    "w = tf.Variable(tf.random_normal(shape=[784, 10], stddev=0.01), name='weights')\n",
    "b = tf.Variable(tf.zeros([1, 10]), name=\"bias\")\n",
    "\n",
    "# Step 4: build model\n",
    "# the model that returns the logits.\n",
    "# this logits will be later passed through softmax layer\n",
    "# to get the probability distribution of possible label of the image\n",
    "# DO NOT DO SOFTMAX HERE\n",
    "logits = tf.matmul(X, w) + b \n",
    "    # apply dropout\n",
    "#logits = tf.nn.dropout(logits, dropout, name='logit_dropout')\n",
    "\n",
    "\n",
    "# Step 5: define loss function\n",
    "# use cross entropy loss of the real labels with the softmax of logits\n",
    "# use the method:\n",
    "# tf.nn.softmax_cross_entropy_with_logits(logits, Y)\n",
    "# then use tf.reduce_mean to get the mean loss of the batch\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y, name='loss')\n",
    "loss = tf.reduce_mean(entropy) # computes the mean over all the examples in the batch\n",
    "\n",
    "# Step 6: define training op\n",
    "# using gradient descent to minimize loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('./graphs/logistic_reg', sess.graph) # to visualize using TensorBoard\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\t\n",
    "    n_batches = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(n_epochs): # train the model n_epochs times\n",
    "        total_loss = 0\n",
    "\n",
    "        for _ in range(n_batches):\n",
    "            X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = deskewAll(X_batch)\n",
    "            _, loss_batch = sess.run([optimizer, loss], feed_dict={X: X_batch, Y:Y_batch})\n",
    "            total_loss += loss_batch\n",
    "        print('Average loss epoch {0}: {1}'.format(i, total_loss/n_batches))\n",
    "\n",
    "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "    print('Optimization Finished!') # should be around 0.35 after 25 epochs\n",
    "\n",
    "    # test the model\n",
    "    n_batches = int(mnist.test.num_examples/batch_size)\n",
    "    total_correct_preds = 0\n",
    "    for i in range(n_batches):\n",
    "        X_batch, Y_batch = mnist.test.next_batch(batch_size)\n",
    "        X_batch = deskewAll(X_batch)\n",
    "        _, loss_batch, logits_batch = sess.run([optimizer, loss, logits], feed_dict={X: X_batch, Y:Y_batch})\n",
    "        preds = tf.nn.softmax(logits_batch)\n",
    "        correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y_batch, 1))\n",
    "        accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32)) # need numpy.count_nonzero(boolarr) :(\n",
    "        total_correct_preds += sess.run(accuracy)\n",
    "\n",
    "    print('Accuracy {0}'.format(total_correct_preds/mnist.test.num_examples))\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just running code from Q3 with more epochs easily gets the 98% accuracy required for the question as we can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-645a83e6009b>:24: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-1-645a83e6009b>:141: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/convnet_mnist/mnist-convnet-2139\n",
      "Average loss at step 2150:  56.3\n",
      "Average loss at step 2160:  44.4\n",
      "Average loss at step 2170:  44.5\n",
      "Average loss at step 2180:  67.7\n",
      "Average loss at step 2190:  80.5\n",
      "Average loss at step 2200:  75.4\n",
      "Average loss at step 2210:  53.5\n",
      "Average loss at step 2220:  59.1\n",
      "Average loss at step 2230:  41.9\n",
      "Average loss at step 2240:  86.6\n",
      "Average loss at step 2250:  48.8\n",
      "Average loss at step 2260:  76.5\n",
      "Average loss at step 2270:  97.4\n",
      "Average loss at step 2280:  56.5\n",
      "Average loss at step 2290:  56.1\n",
      "Average loss at step 2300:  54.2\n",
      "Average loss at step 2310:  52.3\n",
      "Average loss at step 2320:  68.6\n",
      "Average loss at step 2330:  38.2\n",
      "Average loss at step 2340:  63.1\n",
      "Average loss at step 2350:  33.9\n",
      "Average loss at step 2360:  44.8\n",
      "Average loss at step 2370:  61.8\n",
      "Average loss at step 2380:  57.0\n",
      "Average loss at step 2390:  43.8\n",
      "Average loss at step 2400:  57.4\n",
      "Average loss at step 2410:  62.9\n",
      "Average loss at step 2420:  61.1\n",
      "Average loss at step 2430:  18.7\n",
      "Average loss at step 2440:  56.3\n",
      "Average loss at step 2450:  53.9\n",
      "Average loss at step 2460:  54.1\n",
      "Average loss at step 2470:  70.6\n",
      "Average loss at step 2480:  64.0\n",
      "Average loss at step 2490:  37.0\n",
      "Average loss at step 2500:  78.2\n",
      "Average loss at step 2510:  49.2\n",
      "Average loss at step 2520:  53.8\n",
      "Average loss at step 2530:  54.6\n",
      "Average loss at step 2540:  71.6\n",
      "Average loss at step 2550:  52.1\n",
      "Average loss at step 2560:  62.5\n",
      "Average loss at step 2570:  76.7\n",
      "Average loss at step 2580:  52.0\n",
      "Average loss at step 2590:  32.0\n",
      "Average loss at step 2600:  62.2\n",
      "Average loss at step 2610:  56.5\n",
      "Average loss at step 2620:  53.1\n",
      "Average loss at step 2630:  63.6\n",
      "Average loss at step 2640:  52.5\n",
      "Average loss at step 2650:  49.6\n",
      "Average loss at step 2660:  34.6\n",
      "Average loss at step 2670:  71.9\n",
      "Average loss at step 2680:  46.1\n",
      "Average loss at step 2690:  50.4\n",
      "Average loss at step 2700:  59.8\n",
      "Average loss at step 2710:  41.5\n",
      "Average loss at step 2720:  30.5\n",
      "Average loss at step 2730:  60.6\n",
      "Average loss at step 2740:  54.9\n",
      "Average loss at step 2750:  38.3\n",
      "Average loss at step 2760:  43.2\n",
      "Average loss at step 2770:  33.7\n",
      "Average loss at step 2780:  31.6\n",
      "Average loss at step 2790:  46.4\n",
      "Average loss at step 2800:  40.0\n",
      "Average loss at step 2810:  39.5\n",
      "Average loss at step 2820:  38.2\n",
      "Average loss at step 2830:  28.7\n",
      "Average loss at step 2840:  28.3\n",
      "Average loss at step 2850:  45.6\n",
      "Average loss at step 2860:  48.4\n",
      "Average loss at step 2870:  28.1\n",
      "Average loss at step 2880:  28.9\n",
      "Average loss at step 2890:  53.8\n",
      "Average loss at step 2900:  43.0\n",
      "Average loss at step 2910:  39.5\n",
      "Average loss at step 2920:  32.0\n",
      "Average loss at step 2930:  46.4\n",
      "Average loss at step 2940:  50.3\n",
      "Average loss at step 2950:  60.3\n",
      "Average loss at step 2960:  56.6\n",
      "Average loss at step 2970:  51.7\n",
      "Average loss at step 2980:  42.8\n",
      "Average loss at step 2990:  41.5\n",
      "Average loss at step 3000:  29.6\n",
      "Average loss at step 3010:  23.2\n",
      "Average loss at step 3020:  29.4\n",
      "Average loss at step 3030:  24.2\n",
      "Average loss at step 3040:  35.6\n",
      "Average loss at step 3050:  36.4\n",
      "Average loss at step 3060:  27.8\n",
      "Average loss at step 3070:  40.0\n",
      "Average loss at step 3080:  58.9\n",
      "Average loss at step 3090:  23.0\n",
      "Average loss at step 3100:  35.4\n",
      "Average loss at step 3110:  57.3\n",
      "Average loss at step 3120:  42.4\n",
      "Average loss at step 3130:  34.1\n",
      "Average loss at step 3140:  36.1\n",
      "Average loss at step 3150:  44.7\n",
      "Average loss at step 3160:  17.0\n",
      "Average loss at step 3170:  38.9\n",
      "Average loss at step 3180:  33.7\n",
      "Average loss at step 3190:  19.0\n",
      "Average loss at step 3200:  46.1\n",
      "Average loss at step 3210:  27.3\n",
      "Average loss at step 3220:  54.9\n",
      "Average loss at step 3230:  45.2\n",
      "Average loss at step 3240:  37.5\n",
      "Average loss at step 3250:  57.3\n",
      "Average loss at step 3260:  34.5\n",
      "Average loss at step 3270:  60.9\n",
      "Average loss at step 3280:  44.2\n",
      "Average loss at step 3290:  36.9\n",
      "Average loss at step 3300:  44.9\n",
      "Average loss at step 3310:  32.0\n",
      "Average loss at step 3320:  28.8\n",
      "Average loss at step 3330:  28.3\n",
      "Average loss at step 3340:  36.2\n",
      "Average loss at step 3350:  38.1\n",
      "Average loss at step 3360:  35.9\n",
      "Average loss at step 3370:  37.0\n",
      "Average loss at step 3380:  16.2\n",
      "Average loss at step 3390:  52.4\n",
      "Average loss at step 3400:  37.6\n",
      "Average loss at step 3410:  39.2\n",
      "Average loss at step 3420:  38.4\n",
      "Average loss at step 3430:  28.3\n",
      "Average loss at step 3440:  12.6\n",
      "Average loss at step 3450:  37.9\n",
      "Average loss at step 3460:  12.1\n",
      "Average loss at step 3470:  12.2\n",
      "Average loss at step 3480:  24.7\n",
      "Average loss at step 3490:  31.6\n",
      "Average loss at step 3500:  31.2\n",
      "Average loss at step 3510:  40.0\n",
      "Average loss at step 3520:  40.8\n",
      "Average loss at step 3530:  31.3\n",
      "Average loss at step 3540:  27.9\n",
      "Average loss at step 3550:  28.7\n",
      "Average loss at step 3560:  32.6\n",
      "Average loss at step 3570:  22.6\n",
      "Average loss at step 3580:  39.7\n",
      "Average loss at step 3590:  25.1\n",
      "Average loss at step 3600:  26.6\n",
      "Average loss at step 3610:  29.0\n",
      "Average loss at step 3620:  32.3\n",
      "Average loss at step 3630:  17.3\n",
      "Average loss at step 3640:  27.6\n",
      "Average loss at step 3650:  22.6\n",
      "Average loss at step 3660:  38.4\n",
      "Average loss at step 3670:  14.1\n",
      "Average loss at step 3680:  24.4\n",
      "Average loss at step 3690:  46.9\n",
      "Average loss at step 3700:  29.0\n",
      "Average loss at step 3710:  21.0\n",
      "Average loss at step 3720:  38.5\n",
      "Average loss at step 3730:  20.5\n",
      "Average loss at step 3740:  32.3\n",
      "Average loss at step 3750:  36.6\n",
      "Average loss at step 3760:  16.4\n",
      "Average loss at step 3770:  26.8\n",
      "Average loss at step 3780:  48.7\n",
      "Average loss at step 3790:  33.0\n",
      "Average loss at step 3800:  17.7\n",
      "Average loss at step 3810:  29.0\n",
      "Average loss at step 3820:  23.4\n",
      "Average loss at step 3830:  26.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 3840:  33.5\n",
      "Average loss at step 3850:  37.8\n",
      "Average loss at step 3860:  21.0\n",
      "Average loss at step 3870:  29.0\n",
      "Average loss at step 3880:  28.7\n",
      "Average loss at step 3890:  15.1\n",
      "Average loss at step 3900:  19.5\n",
      "Average loss at step 3910:  17.4\n",
      "Average loss at step 3920:  25.4\n",
      "Average loss at step 3930:  21.5\n",
      "Average loss at step 3940:  16.5\n",
      "Average loss at step 3950:  29.2\n",
      "Average loss at step 3960:  17.5\n",
      "Average loss at step 3970:   7.5\n",
      "Average loss at step 3980:  16.8\n",
      "Average loss at step 3990:  35.0\n",
      "Average loss at step 4000:  26.3\n",
      "Average loss at step 4010:  20.9\n",
      "Average loss at step 4020:  35.2\n",
      "Average loss at step 4030:  19.4\n",
      "Average loss at step 4040:  32.8\n",
      "Average loss at step 4050:  25.1\n",
      "Average loss at step 4060:  12.5\n",
      "Average loss at step 4070:  29.4\n",
      "Average loss at step 4080:  11.9\n",
      "Average loss at step 4090:  25.3\n",
      "Average loss at step 4100:  28.1\n",
      "Average loss at step 4110:  20.2\n",
      "Average loss at step 4120:  16.6\n",
      "Average loss at step 4130:  26.8\n",
      "Average loss at step 4140:  21.7\n",
      "Average loss at step 4150:  35.2\n",
      "Average loss at step 4160:  33.7\n",
      "Average loss at step 4170:  17.7\n",
      "Average loss at step 4180:  21.1\n",
      "Average loss at step 4190:  33.4\n",
      "Average loss at step 4200:  34.5\n",
      "Average loss at step 4210:  23.0\n",
      "Average loss at step 4220:  15.2\n",
      "Average loss at step 4230:  13.1\n",
      "Average loss at step 4240:  20.4\n",
      "Average loss at step 4250:  22.9\n",
      "Average loss at step 4260:  17.8\n",
      "Average loss at step 4270:  31.5\n",
      "Average loss at step 4280:  25.3\n",
      "Average loss at step 4290:  20.5\n",
      "Average loss at step 4300:   9.8\n",
      "Average loss at step 4310:  20.1\n",
      "Average loss at step 4320:  24.0\n",
      "Average loss at step 4330:  15.3\n",
      "Average loss at step 4340:  31.6\n",
      "Average loss at step 4350:  24.6\n",
      "Average loss at step 4360:  21.9\n",
      "Average loss at step 4370:  17.4\n",
      "Average loss at step 4380:  23.6\n",
      "Average loss at step 4390:  10.9\n",
      "Average loss at step 4400:  21.2\n",
      "Average loss at step 4410:  14.4\n",
      "Average loss at step 4420:  27.2\n",
      "Average loss at step 4430:  20.6\n",
      "Average loss at step 4440:   9.7\n",
      "Average loss at step 4450:  11.6\n",
      "Average loss at step 4460:  27.9\n",
      "Average loss at step 4470:  14.3\n",
      "Average loss at step 4480:  25.3\n",
      "Average loss at step 4490:  25.7\n",
      "Average loss at step 4500:  31.8\n",
      "Average loss at step 4510:  14.8\n",
      "Average loss at step 4520:  24.5\n",
      "Average loss at step 4530:  11.9\n",
      "Average loss at step 4540:  11.1\n",
      "Average loss at step 4550:   4.4\n",
      "Average loss at step 4560:  29.8\n",
      "Average loss at step 4570:  19.7\n",
      "Average loss at step 4580:   4.8\n",
      "Average loss at step 4590:  14.0\n",
      "Average loss at step 4600:  15.6\n",
      "Average loss at step 4610:  30.2\n",
      "Average loss at step 4620:  23.6\n",
      "Average loss at step 4630:  14.2\n",
      "Average loss at step 4640:  30.7\n",
      "Average loss at step 4650:  16.2\n",
      "Average loss at step 4660:  17.0\n",
      "Average loss at step 4670:  14.3\n",
      "Average loss at step 4680:  29.1\n",
      "Average loss at step 4690:  17.0\n",
      "Average loss at step 4700:  19.2\n",
      "Average loss at step 4710:  27.3\n",
      "Average loss at step 4720:  13.0\n",
      "Average loss at step 4730:   6.7\n",
      "Average loss at step 4740:  10.3\n",
      "Average loss at step 4750:  20.5\n",
      "Average loss at step 4760:   5.9\n",
      "Average loss at step 4770:  25.2\n",
      "Average loss at step 4780:  17.1\n",
      "Average loss at step 4790:  15.2\n",
      "Average loss at step 4800:  16.3\n",
      "Average loss at step 4810:  10.8\n",
      "Average loss at step 4820:  14.1\n",
      "Average loss at step 4830:  24.2\n",
      "Average loss at step 4840:  23.2\n",
      "Average loss at step 4850:  20.7\n",
      "Average loss at step 4860:  41.9\n",
      "Average loss at step 4870:  23.7\n",
      "Average loss at step 4880:  16.5\n",
      "Average loss at step 4890:  16.9\n",
      "Average loss at step 4900:  24.7\n",
      "Average loss at step 4910:  19.5\n",
      "Average loss at step 4920:  16.4\n",
      "Average loss at step 4930:  25.6\n",
      "Average loss at step 4940:  17.9\n",
      "Average loss at step 4950:  20.9\n",
      "Average loss at step 4960:  16.6\n",
      "Average loss at step 4970:   8.3\n",
      "Average loss at step 4980:  13.2\n",
      "Average loss at step 4990:  21.3\n",
      "Average loss at step 5000:  10.8\n",
      "Average loss at step 5010:  15.1\n",
      "Average loss at step 5020:  17.5\n",
      "Average loss at step 5030:  14.1\n",
      "Average loss at step 5040:  12.1\n",
      "Average loss at step 5050:  24.7\n",
      "Average loss at step 5060:  15.9\n",
      "Average loss at step 5070:  17.1\n",
      "Average loss at step 5080:  14.3\n",
      "Average loss at step 5090:   6.0\n",
      "Average loss at step 5100:  30.2\n",
      "Average loss at step 5110:  18.5\n",
      "Average loss at step 5120:  11.1\n",
      "Average loss at step 5130:  15.6\n",
      "Average loss at step 5140:  14.4\n",
      "Average loss at step 5150:  23.3\n",
      "Average loss at step 5160:   7.7\n",
      "Average loss at step 5170:  10.7\n",
      "Average loss at step 5180:   7.4\n",
      "Average loss at step 5190:  16.3\n",
      "Average loss at step 5200:   7.6\n",
      "Average loss at step 5210:   6.9\n",
      "Average loss at step 5220:  23.1\n",
      "Average loss at step 5230:  17.4\n",
      "Average loss at step 5240:  14.8\n",
      "Average loss at step 5250:   5.0\n",
      "Average loss at step 5260:  12.1\n",
      "Average loss at step 5270:  12.4\n",
      "Average loss at step 5280:  15.3\n",
      "Average loss at step 5290:  14.2\n",
      "Average loss at step 5300:  15.8\n",
      "Average loss at step 5310:  16.6\n",
      "Average loss at step 5320:  16.2\n",
      "Average loss at step 5330:  21.9\n",
      "Average loss at step 5340:  15.1\n",
      "Average loss at step 5350:  11.7\n",
      "Average loss at step 5360:  19.0\n",
      "Average loss at step 5370:  13.2\n",
      "Average loss at step 5380:  19.0\n",
      "Average loss at step 5390:  13.2\n",
      "Average loss at step 5400:  21.2\n",
      "Average loss at step 5410:  15.0\n",
      "Average loss at step 5420:  16.3\n",
      "Average loss at step 5430:  12.3\n",
      "Average loss at step 5440:  15.1\n",
      "Average loss at step 5450:  23.1\n",
      "Average loss at step 5460:  19.1\n",
      "Average loss at step 5470:  16.6\n",
      "Average loss at step 5480:  13.8\n",
      "Average loss at step 5490:  15.2\n",
      "Average loss at step 5500:  12.3\n",
      "Average loss at step 5510:  14.2\n",
      "Average loss at step 5520:  17.1\n",
      "Average loss at step 5530:  23.8\n",
      "Average loss at step 5540:  22.9\n",
      "Average loss at step 5550:  18.0\n",
      "Average loss at step 5560:  14.0\n",
      "Average loss at step 5570:   7.3\n",
      "Average loss at step 5580:  23.0\n",
      "Average loss at step 5590:   8.9\n",
      "Average loss at step 5600:   8.8\n",
      "Average loss at step 5610:  12.7\n",
      "Average loss at step 5620:   7.5\n",
      "Average loss at step 5630:  21.4\n",
      "Average loss at step 5640:   7.5\n",
      "Average loss at step 5650:   9.0\n",
      "Average loss at step 5660:   7.5\n",
      "Average loss at step 5670:   5.9\n",
      "Average loss at step 5680:   9.0\n",
      "Average loss at step 5690:  12.2\n",
      "Average loss at step 5700:   8.5\n",
      "Average loss at step 5710:  15.1\n",
      "Average loss at step 5720:  16.6\n",
      "Average loss at step 5730:  19.6\n",
      "Average loss at step 5740:  18.9\n",
      "Average loss at step 5750:  13.8\n",
      "Average loss at step 5760:  16.5\n",
      "Average loss at step 5770:  19.3\n",
      "Average loss at step 5780:   6.9\n",
      "Average loss at step 5790:  14.5\n",
      "Average loss at step 5800:  19.4\n",
      "Average loss at step 5810:  13.9\n",
      "Average loss at step 5820:  21.0\n",
      "Average loss at step 5830:  17.3\n",
      "Average loss at step 5840:   9.7\n",
      "Average loss at step 5850:  17.3\n",
      "Average loss at step 5860:  12.5\n",
      "Average loss at step 5870:  13.5\n",
      "Average loss at step 5880:  11.9\n",
      "Average loss at step 5890:   5.8\n",
      "Average loss at step 5900:  11.4\n",
      "Average loss at step 5910:   9.1\n",
      "Average loss at step 5920:  14.8\n",
      "Average loss at step 5930:  11.8\n",
      "Average loss at step 5940:  13.6\n",
      "Average loss at step 5950:  13.0\n",
      "Average loss at step 5960:   9.3\n",
      "Average loss at step 5970:  12.1\n",
      "Average loss at step 5980:  12.7\n",
      "Average loss at step 5990:  26.4\n",
      "Average loss at step 6000:  14.0\n",
      "Average loss at step 6010:  10.3\n",
      "Average loss at step 6020:  11.6\n",
      "Average loss at step 6030:  11.5\n",
      "Average loss at step 6040:   5.5\n",
      "Average loss at step 6050:   9.9\n",
      "Average loss at step 6060:  12.1\n",
      "Average loss at step 6070:  12.2\n",
      "Average loss at step 6080:  15.1\n",
      "Average loss at step 6090:  13.4\n",
      "Average loss at step 6100:  15.5\n",
      "Average loss at step 6110:  13.6\n",
      "Average loss at step 6120:  12.0\n",
      "Average loss at step 6130:  19.2\n",
      "Average loss at step 6140:   5.4\n",
      "Average loss at step 6150:  20.4\n",
      "Average loss at step 6160:  13.1\n",
      "Average loss at step 6170:   3.6\n",
      "Average loss at step 6180:  10.1\n",
      "Average loss at step 6190:  16.8\n",
      "Average loss at step 6200:  14.6\n",
      "Average loss at step 6210:  22.2\n",
      "Average loss at step 6220:   4.9\n",
      "Average loss at step 6230:   9.9\n",
      "Average loss at step 6240:  14.1\n",
      "Average loss at step 6250:   9.8\n",
      "Average loss at step 6260:   7.8\n",
      "Average loss at step 6270:  12.7\n",
      "Average loss at step 6280:  12.6\n",
      "Average loss at step 6290:  10.0\n",
      "Average loss at step 6300:  20.6\n",
      "Average loss at step 6310:  13.9\n",
      "Average loss at step 6320:   7.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 6330:  10.6\n",
      "Average loss at step 6340:   9.4\n",
      "Average loss at step 6350:  14.2\n",
      "Average loss at step 6360:  11.1\n",
      "Average loss at step 6370:   7.6\n",
      "Average loss at step 6380:   7.9\n",
      "Average loss at step 6390:   8.9\n",
      "Average loss at step 6400:  13.5\n",
      "Average loss at step 6410:  11.9\n",
      "Average loss at step 6420:  12.0\n",
      "Average loss at step 6430:  12.7\n",
      "Average loss at step 6440:   9.6\n",
      "Average loss at step 6450:  13.3\n",
      "Average loss at step 6460:   3.9\n",
      "Average loss at step 6470:  11.4\n",
      "Average loss at step 6480:  10.4\n",
      "Average loss at step 6490:  14.4\n",
      "Average loss at step 6500:  15.3\n",
      "Average loss at step 6510:   5.1\n",
      "Average loss at step 6520:  15.3\n",
      "Average loss at step 6530:  13.7\n",
      "Average loss at step 6540:  12.5\n",
      "Average loss at step 6550:   8.8\n",
      "Average loss at step 6560:   6.7\n",
      "Average loss at step 6570:  11.0\n",
      "Average loss at step 6580:  15.7\n",
      "Average loss at step 6590:  10.6\n",
      "Average loss at step 6600:  15.1\n",
      "Average loss at step 6610:  11.1\n",
      "Average loss at step 6620:   6.5\n",
      "Average loss at step 6630:  12.2\n",
      "Average loss at step 6640:  20.2\n",
      "Average loss at step 6650:   7.4\n",
      "Average loss at step 6660:   3.6\n",
      "Average loss at step 6670:  12.6\n",
      "Average loss at step 6680:   4.5\n",
      "Average loss at step 6690:  15.1\n",
      "Average loss at step 6700:  11.3\n",
      "Average loss at step 6710:  16.9\n",
      "Average loss at step 6720:   2.7\n",
      "Average loss at step 6730:  11.1\n",
      "Average loss at step 6740:   5.6\n",
      "Average loss at step 6750:   5.3\n",
      "Average loss at step 6760:  20.5\n",
      "Average loss at step 6770:  13.6\n",
      "Average loss at step 6780:  13.5\n",
      "Average loss at step 6790:   6.4\n",
      "Average loss at step 6800:  19.6\n",
      "Average loss at step 6810:   9.3\n",
      "Average loss at step 6820:  15.8\n",
      "Average loss at step 6830:   9.4\n",
      "Average loss at step 6840:  20.7\n",
      "Average loss at step 6850:  25.5\n",
      "Average loss at step 6860:   8.8\n",
      "Average loss at step 6870:  10.2\n",
      "Average loss at step 6880:   5.1\n",
      "Average loss at step 6890:   9.2\n",
      "Average loss at step 6900:   8.6\n",
      "Average loss at step 6910:  16.8\n",
      "Average loss at step 6920:  14.7\n",
      "Average loss at step 6930:   8.3\n",
      "Average loss at step 6940:   8.5\n",
      "Average loss at step 6950:   9.2\n",
      "Average loss at step 6960:  15.7\n",
      "Average loss at step 6970:  10.3\n",
      "Average loss at step 6980:   5.2\n",
      "Average loss at step 6990:   5.7\n",
      "Average loss at step 7000:   2.7\n",
      "Average loss at step 7010:   9.9\n",
      "Average loss at step 7020:  15.4\n",
      "Average loss at step 7030:  17.7\n",
      "Average loss at step 7040:   8.8\n",
      "Average loss at step 7050:  12.8\n",
      "Average loss at step 7060:  18.7\n",
      "Average loss at step 7070:   9.4\n",
      "Average loss at step 7080:  13.3\n",
      "Average loss at step 7090:  18.3\n",
      "Average loss at step 7100:  13.3\n",
      "Average loss at step 7110:   8.4\n",
      "Average loss at step 7120:  11.5\n",
      "Average loss at step 7130:  18.2\n",
      "Average loss at step 7140:   9.3\n",
      "Average loss at step 7150:   4.5\n",
      "Average loss at step 7160:   2.4\n",
      "Average loss at step 7170:   4.1\n",
      "Average loss at step 7180:  11.6\n",
      "Average loss at step 7190:   8.8\n",
      "Average loss at step 7200:  11.1\n",
      "Average loss at step 7210:  12.9\n",
      "Average loss at step 7220:   6.1\n",
      "Average loss at step 7230:  16.6\n",
      "Average loss at step 7240:   9.1\n",
      "Average loss at step 7250:  11.7\n",
      "Average loss at step 7260:   8.9\n",
      "Average loss at step 7270:  19.9\n",
      "Average loss at step 7280:  14.2\n",
      "Average loss at step 7290:  10.0\n",
      "Average loss at step 7300:  10.0\n",
      "Average loss at step 7310:   8.7\n",
      "Average loss at step 7320:   8.8\n",
      "Average loss at step 7330:  15.1\n",
      "Average loss at step 7340:   7.5\n",
      "Average loss at step 7350:  12.6\n",
      "Average loss at step 7360:   6.2\n",
      "Average loss at step 7370:  14.6\n",
      "Average loss at step 7380:   5.3\n",
      "Average loss at step 7390:   6.6\n",
      "Average loss at step 7400:  12.5\n",
      "Average loss at step 7410:   3.5\n",
      "Average loss at step 7420:  13.0\n",
      "Average loss at step 7430:   3.3\n",
      "Average loss at step 7440:  12.2\n",
      "Average loss at step 7450:  12.3\n",
      "Average loss at step 7460:   4.3\n",
      "Average loss at step 7470:   2.4\n",
      "Average loss at step 7480:  16.3\n",
      "Average loss at step 7490:  10.6\n",
      "Average loss at step 7500:   7.7\n",
      "Average loss at step 7510:  12.1\n",
      "Average loss at step 7520:  12.9\n",
      "Average loss at step 7530:  15.4\n",
      "Average loss at step 7540:   8.2\n",
      "Average loss at step 7550:   4.9\n",
      "Average loss at step 7560:   7.3\n",
      "Average loss at step 7570:   5.6\n",
      "Average loss at step 7580:   9.6\n",
      "Average loss at step 7590:  11.7\n",
      "Average loss at step 7600:   8.7\n",
      "Average loss at step 7610:   6.4\n",
      "Average loss at step 7620:  10.2\n",
      "Average loss at step 7630:  12.5\n",
      "Average loss at step 7640:   3.8\n",
      "Average loss at step 7650:  14.9\n",
      "Average loss at step 7660:  14.2\n",
      "Average loss at step 7670:   9.3\n",
      "Average loss at step 7680:   9.5\n",
      "Average loss at step 7690:  15.1\n",
      "Average loss at step 7700:   8.6\n",
      "Average loss at step 7710:  10.1\n",
      "Average loss at step 7720:   5.6\n",
      "Average loss at step 7730:   3.5\n",
      "Average loss at step 7740:  17.5\n",
      "Average loss at step 7750:   3.7\n",
      "Average loss at step 7760:   4.6\n",
      "Average loss at step 7770:   6.5\n",
      "Average loss at step 7780:  17.7\n",
      "Average loss at step 7790:   6.3\n",
      "Average loss at step 7800:   6.9\n",
      "Average loss at step 7810:  13.7\n",
      "Average loss at step 7820:   1.2\n",
      "Average loss at step 7830:   4.6\n",
      "Average loss at step 7840:   3.0\n",
      "Average loss at step 7850:  16.5\n",
      "Average loss at step 7860:   7.0\n",
      "Average loss at step 7870:   4.7\n",
      "Average loss at step 7880:  14.1\n",
      "Average loss at step 7890:   9.7\n",
      "Average loss at step 7900:  13.4\n",
      "Average loss at step 7910:  12.0\n",
      "Average loss at step 7920:   4.7\n",
      "Average loss at step 7930:  17.2\n",
      "Average loss at step 7940:  12.7\n",
      "Average loss at step 7950:  12.3\n",
      "Average loss at step 7960:   9.4\n",
      "Average loss at step 7970:  20.3\n",
      "Average loss at step 7980:   3.7\n",
      "Average loss at step 7990:   9.6\n",
      "Average loss at step 8000:   8.2\n",
      "Average loss at step 8010:   8.4\n",
      "Average loss at step 8020:  14.3\n",
      "Average loss at step 8030:   6.8\n",
      "Average loss at step 8040:   8.8\n",
      "Average loss at step 8050:  10.8\n",
      "Average loss at step 8060:   8.1\n",
      "Average loss at step 8070:   7.8\n",
      "Average loss at step 8080:   7.4\n",
      "Average loss at step 8090:  11.1\n",
      "Average loss at step 8100:   5.3\n",
      "Average loss at step 8110:  18.7\n",
      "Average loss at step 8120:  10.2\n",
      "Average loss at step 8130:   6.3\n",
      "Average loss at step 8140:   6.0\n",
      "Average loss at step 8150:   6.6\n",
      "Average loss at step 8160:   5.0\n",
      "Average loss at step 8170:  14.7\n",
      "Average loss at step 8180:   5.2\n",
      "Average loss at step 8190:  11.9\n",
      "Average loss at step 8200:   4.7\n",
      "Average loss at step 8210:   5.4\n",
      "Average loss at step 8220:   3.5\n",
      "Average loss at step 8230:   1.9\n",
      "Average loss at step 8240:   3.8\n",
      "Average loss at step 8250:   7.0\n",
      "Average loss at step 8260:   5.8\n",
      "Average loss at step 8270:  10.3\n",
      "Average loss at step 8280:   3.2\n",
      "Average loss at step 8290:   1.4\n",
      "Average loss at step 8300:   5.1\n",
      "Average loss at step 8310:   4.9\n",
      "Average loss at step 8320:   9.1\n",
      "Average loss at step 8330:   8.4\n",
      "Average loss at step 8340:   2.1\n",
      "Average loss at step 8350:   9.8\n",
      "Average loss at step 8360:   3.7\n",
      "Average loss at step 8370:  11.5\n",
      "Average loss at step 8380:   5.7\n",
      "Average loss at step 8390:   6.3\n",
      "Average loss at step 8400:  10.2\n",
      "Average loss at step 8410:   8.6\n",
      "Average loss at step 8420:  11.7\n",
      "Average loss at step 8430:   9.3\n",
      "Average loss at step 8440:  10.0\n",
      "Average loss at step 8450:  10.8\n",
      "Average loss at step 8460:   9.6\n",
      "Average loss at step 8470:   8.5\n",
      "Average loss at step 8480:  10.2\n",
      "Average loss at step 8490:   7.4\n",
      "Average loss at step 8500:   6.8\n",
      "Average loss at step 8510:   8.6\n",
      "Average loss at step 8520:   9.5\n",
      "Average loss at step 8530:   2.7\n",
      "Average loss at step 8540:   7.3\n",
      "Average loss at step 8550:  14.0\n",
      "Average loss at step 8560:  17.4\n",
      "Average loss at step 8570:  22.7\n",
      "Average loss at step 8580:   7.5\n",
      "Optimization Finished!\n",
      "Total time: 1865.6100680828094 seconds\n",
      "Accuracy 0.9769\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Using convolutional net on MNIST dataset of handwritten digit\n",
    "(http://yann.lecun.com/exdb/mnist/)\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#import utils\n",
    "\n",
    "N_CLASSES = 10\n",
    "\n",
    "# Step 1: Read in data\n",
    "# using TF Learn's built in function to load MNIST data to the folder data/mnist\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "\n",
    "# Step 2: Define paramaters for the model\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "SKIP_STEP = 100\n",
    "DROPOUT = 0.75\n",
    "N_EPOCHS = 20\n",
    "\n",
    "# Step 3: create placeholders for features and labels\n",
    "# each image in the MNIST data is of shape 28*28 = 784\n",
    "# therefore, each image is represented with a 1x784 tensor\n",
    "# We'll be doing dropout for hidden layer so we'll need a placeholder\n",
    "# for the dropout probability too\n",
    "# Use None for shape so we can change the batch_size once we've built the graph\n",
    "with tf.name_scope('data'):\n",
    "    X = tf.placeholder(tf.float32, [None, 784], name=\"X_placeholder\")\n",
    "    Y = tf.placeholder(tf.float32, [None, 10], name=\"Y_placeholder\")\n",
    "\n",
    "dropout = tf.placeholder(tf.float32, name='dropout')\n",
    "\n",
    "# Step 4 + 5: create weights + do inference\n",
    "# the model is conv -> relu -> pool -> conv -> relu -> pool -> fully connected -> softmax\n",
    "\n",
    "global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "\n",
    "#utils.make_dir('checkpoints')\n",
    "#utils.make_dir('checkpoints/convnet_mnist')\n",
    "\n",
    "with tf.variable_scope('conv1') as scope:\n",
    "    # first, reshape the image to [BATCH_SIZE, 28, 28, 1] to make it work with tf.nn.conv2d\n",
    "    # use the dynamic dimension -1\n",
    "    images = tf.reshape(X, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # TO DO\n",
    "\n",
    "    # create kernel variable of dimension [5, 5, 1, 32]\n",
    "    # use tf.truncated_normal_initializer()\n",
    "\n",
    "    kernel = tf.get_variable('kernel', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "    # create biases variable of dimension [32]\n",
    "    # use tf.constant_initializer(0.0)\n",
    "    biases = tf.get_variable('biases', [32], initializer=tf.constant_initializer(0.0))\n",
    "    # TO DO\n",
    "\n",
    "    # apply tf.nn.conv2d. strides [1, 1, 1, 1], padding is 'SAME'\n",
    "\n",
    "    conv = tf.nn.conv2d(images, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "    # apply relu on the sum of convolution output and biases\n",
    "\n",
    "    conv1 = tf.nn.relu(conv + biases, name=scope.name)\n",
    "\n",
    "    # output is of dimension BATCH_SIZE x 28 x 28 x 32\n",
    "\n",
    "with tf.variable_scope('pool1') as scope:\n",
    "# apply max pool with ksize [1, 2, 2, 1], and strides [1, 2, 2, 1], padding 'SAME'\n",
    "\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# output is of dimension BATCH_SIZE x 14 x 14 x 32\n",
    "\n",
    "with tf.variable_scope('conv2') as scope:\n",
    "    # similar to conv1, except kernel now is of the size 5 x 5 x 32 x 64\n",
    "    kernel = tf.get_variable('kernels', [5, 5, 32, 64],\n",
    "                             initializer=tf.truncated_normal_initializer())\n",
    "    biases = tf.get_variable('biases', [64],\n",
    "                             initializer=tf.random_normal_initializer())\n",
    "    conv = tf.nn.conv2d(pool1, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    conv2 = tf.nn.relu(conv + biases, name=scope.name)\n",
    "\n",
    "    # output is of dimension BATCH_SIZE x 14 x 14 x 64\n",
    "\n",
    "with tf.variable_scope('pool2') as scope:\n",
    "    # similar to pool1\n",
    "    pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                           padding='SAME')\n",
    "\n",
    "    # output is of dimension BATCH_SIZE x 7 x 7 x 64\n",
    "\n",
    "with tf.variable_scope('fc') as scope:\n",
    "    # use weight of dimension 7 * 7 * 64 x 1024\n",
    "    input_features = 7 * 7 * 64\n",
    "\n",
    "    # create weights and biases\n",
    "\n",
    "    w = tf.get_variable('weights', [input_features, 1024], initializer=tf.truncated_normal_initializer())\n",
    "    b = tf.get_variable('biases', [1024], initializer=tf.random_normal_initializer())\n",
    "\n",
    "    # reshape pool2 to 2 dimensional\n",
    "    pool2 = tf.reshape(pool2, [-1, input_features])\n",
    "\n",
    "    # apply relu on matmul of pool2 and w + b\n",
    "    fc = tf.nn.relu(tf.matmul(pool2, w) + b, name='relu')\n",
    "\n",
    "    # TO DO\n",
    "\n",
    "    # apply dropout\n",
    "    fc = tf.nn.dropout(fc, dropout, name='relu_dropout')\n",
    "\n",
    "with tf.variable_scope('softmax_linear') as scope:\n",
    "# this you should know. get logits without softmax\n",
    "# you need to create weights and biases\n",
    "\n",
    "    w = tf.get_variable('weights', [1024, 10], initializer=tf.truncated_normal_initializer())\n",
    "    b = tf.get_variable('biases', [10], initializer=tf.random_normal_initializer())\n",
    "\n",
    "# Step 6: define loss function\n",
    "# use softmax cross entropy with logits as the loss function\n",
    "# compute mean cross entropy, softmax is applied internally\n",
    "    logits = tf.matmul(fc, w) + b\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "# you should know how to do this too\n",
    "\n",
    "    entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y)\n",
    "    loss = tf.reduce_mean(entropy, name='loss')\n",
    "\n",
    "# Step 7: define training op\n",
    "# using gradient descent with learning rate of LEARNING_RATE to minimize cost\n",
    "# don't forgot to pass in global_step\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss, global_step=global_step)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    # to visualize using TensorBoard\n",
    "    #writer = tf.summary.FileWriter('./my_graph/mnist', sess.graph)\n",
    "    ##### You have to create folders to store checkpoints\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/convnet_mnist/checkpoint'))\n",
    "    # if that checkpoint exists, restore from checkpoint\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    initial_step = global_step.eval()\n",
    "\n",
    "    start_time = time.time()\n",
    "    n_batches = int(mnist.train.num_examples / BATCH_SIZE)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    for index in range(initial_step, n_batches * N_EPOCHS):  # train the model n_epochs times\n",
    "        X_batch, Y_batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "        _, loss_batch = sess.run([optimizer, loss],\n",
    "                                 feed_dict={X: X_batch, Y: Y_batch, dropout: DROPOUT})\n",
    "        total_loss += loss_batch\n",
    "        if (index + 1) % SKIP_STEP == 0:\n",
    "            print('Average loss at step {}: {:5.1f}'.format(index + 1, total_loss / SKIP_STEP))\n",
    "            total_loss = 0.0\n",
    "            saver.save(sess, 'checkpoints/convnet_mnist/mnist-convnet', index)\n",
    "\n",
    "    print(\"Optimization Finished!\")  # should be around 0.35 after 25 epochs\n",
    "    print(\"Total time: {0} seconds\".format(time.time() - start_time))\n",
    "\n",
    "    # test the model\n",
    "    n_batches = int(mnist.test.num_examples / BATCH_SIZE)\n",
    "    total_correct_preds = 0\n",
    "    for i in range(n_batches):\n",
    "        X_batch, Y_batch = mnist.test.next_batch(BATCH_SIZE)\n",
    "        _, loss_batch, logits_batch = sess.run([optimizer, loss, logits],\n",
    "                                               feed_dict={X: X_batch, Y: Y_batch, dropout: DROPOUT})\n",
    "        preds = tf.nn.softmax(logits_batch)\n",
    "        correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y_batch, 1))\n",
    "        accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "        total_correct_preds += sess.run(accuracy)\n",
    "\n",
    "    print(\"Accuracy {0}\".format(total_correct_preds / mnist.test.num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
